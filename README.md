## Анализ возможности проведения A/B-тестирования алгоритма рекомендаций

Коллеги из ML-отдела планируют выкатывать новый алгоритм, рекомендующий нашим пользователям интересные посты. По результатам обсуждения были сделаны следующие выводы: Алгоритм добавляет пользователям 1-2 просмотра Вероятность того, что он сработает, составляет 90% Если у пользователя меньше 50 просмотров, то алгоритм не сработает. Возникает предположение, что увеличение числа просмотров приведёт и к увеличению лайков на пользователя.
### Можем ли мы обнаружить различия в среднем количестве лайков на пользователя?
Попробуем ответить на этот вопрос

Стек: pandahouse, pandas, tqdm, seaborn, nump, scipy.stats 

### Этапы работы:
1. Получила доступ к данным, провела предобработку данных;
2. Взяла интересующие метрики и на их основе сгенеровала данные для AA-теста;
3. Провела AA-тест для проверки сгенерированных данных.По результатам теста доля FPR равна 0.05375, что примерно равно значению альфа (0.05). Делаем вывод, что симуляция работает правильно;
4. На основе сгенерированных данных смоделировала эффект алгоритма и посчитала мощность. Получилась мощность где-то в районе 25.6%. Это чудовищно мало. Нужно дальше работать;
5. После улучшения качества алгоритма коллегами пересчитала мощность с новыми условиями. Теперь у нас мощность около 41.7%. Это всё ещё очень мало;
6. После увеличения длительности проведения эксперимента до 2 недель посчитала мощность. Получилось где-то около 56%.  Всё ближе к цели, но заветного порога в 80% мы ещё не достигли;
7. Попробовала изменить подход и провести эксперимент только на тех пользователях, на которых сработал алгоритм. Получила мощность где-то 64.3%. Ближе, но все равно не дотягиваем до 80%

### Вывод: после всех предпринятых попыток так и не получилось добраться до мощности в 80%.

### Есть несколько вариантов развития событий:
* отказаться от идеи эксперимента вообще. Раз у нас не хватает ресурсов для детекции такого изменения, то и смысла особо действовать нет;
* всё равно запустить эксперимент и надеяться на лучшее. Платой за это решение будет меньшая уверенность в полученных результатах;
* дорабатывать алгоритм, чтобы его эффект либо распространялся на большее число пользователей, либо чтобы он был больше.
* попробовать найти бОльшее количество пользователей и пересчитать симуляцию. может, вы всё-таки получится набрать достаточное количество
* поменять уровень значимости на более высокий. Платой за это будет большая вероятность ложноположительного результата.
